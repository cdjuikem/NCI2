{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed92d77",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf945c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c581a663",
   "metadata": {},
   "source": [
    "### 1. Import queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf90adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Query\n",
      "0            Vessel caught misreporting catch amount\n",
      "1              Vessel caught falsifying fishing logs\n",
      "2         Vessel caught with incorrect catch reports\n",
      "3  Vessel caught underreporting catch in North At...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the excel file\n",
    "excel_data = pd.read_excel('PIMS Sample Prompts.xlsx')\n",
    "\n",
    "queries = []\n",
    "for index, row in excel_data.iterrows():\n",
    "    # Process each row\n",
    "    queries.append(row['Prompt'])\n",
    "    \n",
    "queries = queries[:4]\n",
    "queries = pd.DataFrame(queries, columns = ['Query'])\n",
    "print(queries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5945f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f5990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "168fa669",
   "metadata": {},
   "source": [
    "### 2. Data frame initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "237529d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Query, Engine, results, dates, days]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "numbers_and_dates = pd.DataFrame(columns = [\n",
    "    'Query', 'Engine',\n",
    "    'results', 'dates', 'days'\n",
    "])\n",
    "\n",
    "search_results_articles = pd.DataFrame(columns = ['Query', 'Engine','Title', 'Dates', 'Link'])\n",
    "print(numbers_and_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472d69c",
   "metadata": {},
   "source": [
    "### 3. Google, Bing news search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4785520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "# API Scrap functions\n",
    "\n",
    "def google_news_search(query, location = 'Canada'):\n",
    "    params = {\n",
    "        \"api_key\": \"7020efc655aafd1998bfad82b8f96fee27be3cdb26c1bb67909ba7042c56ebd1\",\n",
    "        \"q\": query,\n",
    "        \"tbm\": \"nws\",\n",
    "        \"location\": location,\n",
    "        \"num\": \"30\"\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    news_results = results[\"news_results\"]\n",
    "    return news_results\n",
    "\n",
    "def bing_news_search(query, location = \"CA\"):\n",
    "    params = {\n",
    "      \"api_key\": \"7020efc655aafd1998bfad82b8f96fee27be3cdb26c1bb67909ba7042c56ebd1\",\n",
    "      \"engine\": \"bing_news\",\n",
    "      \"q\": query,\n",
    "      \"cc\": location,\n",
    "      \"count\": \"30\"\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "\n",
    "    news_results = results[\"organic_results\"]\n",
    "    return news_results\n",
    "\n",
    "    \n",
    "def duckduckgo_news_search(query, location = \"ca-en\"):\n",
    "    params = {\n",
    "        \"engine\": \"duckduckgo\",\n",
    "        \"q\": query,\n",
    "        \"kl\": location,\n",
    "        \"tbm\": \"nws\",\n",
    "        #\"api_key\": \"7020efc655aafd1998bfad82b8f96fee27be3cdb26c1bb67909ba7042c56ebd1\"\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    print(results)\n",
    "#    news_results = results[\"news_results\"]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "#duckduckgo_news_search(\"vessel underreport\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec8cd03",
   "metadata": {},
   "source": [
    "### 4. Search and scrap the results (title, dates, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f8120d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "def convert_day(text):\n",
    "    if None:\n",
    "        return None\n",
    "    \n",
    "    pattern1 = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "    pattern2 = r'\\b\\d+[hdwmy]'\n",
    "    pattern3 = r'^\\d{2}/\\d{2}/\\d{4}$'\n",
    "    pattern4 = r'(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+\\d{1,2},\\s+\\d{4}'\n",
    "    pattern5 = r'\\b\\d+(?:hrs|day|mon|wks|yrs)\\b'\n",
    "\n",
    "    if re.match(pattern1, text):\n",
    "        date = datetime.strptime(text, \"%Y-%M-%d\").date()\n",
    "        today = datetime.combine(date.today(), datetime.min.time())\n",
    "        days = str(today - date).days\n",
    "        return int(days[0])\n",
    "    pattern2match = re.findall(pattern2, text)\n",
    "    pattern5match = re.findall(pattern5,text)\n",
    "    if pattern2match:\n",
    "        text = pattern2match[0]\n",
    "        if text[len(text)-1] == 'h':\n",
    "            return 1\n",
    "        if text[len(text)-1] == 'd':\n",
    "            return int(text[:len(text)-1])\n",
    "        if text[len(text)-1] == 'w':\n",
    "            return int(text[:len(text)-1])*7\n",
    "        if text[len(text)-1] == 'm':\n",
    "            return int(text[:len(text)-1])*30\n",
    "        if text[len(text)-1] == 'y':\n",
    "            return int(text[:len(text)-1])*365    \n",
    "        \n",
    "    pattern5match = re.findall(pattern5,text)\n",
    "    if pattern5match:\n",
    "        text = pattern5match[0]\n",
    "        if text[len(text)-1] == 'hrs':\n",
    "            return 1\n",
    "        if text[len(text)-1] == 'day':\n",
    "            return int(text[:len(text)-1])\n",
    "        if text[len(text)-1] == 'wks':\n",
    "            return int(text[:len(text)-1])*7\n",
    "        if text[len(text)-1] == 'mon':\n",
    "            return int(text[:len(text)-1])*30\n",
    "        if text[len(text)-1] == 'yrs':\n",
    "            return int(text[:len(text)-1])*365   \n",
    "        \n",
    "    pattern3match = re.match(pattern3, text)\n",
    "    if pattern3match:\n",
    "        date_format = \"%m/%d/%Y\"\n",
    "        try:\n",
    "            # Parse the input date string into a datetime object\n",
    "            given_date = datetime.strptime(text, date_format).date()\n",
    "            # Get today's date\n",
    "            today = date.today()\n",
    "            # Calculate the difference in days\n",
    "            days_difference = (today - given_date).days\n",
    "            return int(days_difference)\n",
    "        except ValueError:\n",
    "            # Handle invalid date format or other errors\n",
    "            return None\n",
    "        \n",
    "    pattern4match = re.match(pattern4, text)\n",
    "    if pattern4match:\n",
    "        date_format = '%b %d, %Y'\n",
    "        try:\n",
    "            # Parse the input date string into a datetime object\n",
    "            given_date = datetime.strptime(text, date_format).date()\n",
    "            # Get today's date\n",
    "            today = datetime.now().date()\n",
    "            # Calculate the difference in days\n",
    "            days_difference = (today - given_date).days\n",
    "            return int(days_difference)\n",
    "\n",
    "        except ValueError:\n",
    "            # Handle invalid date format or other errors\n",
    "            return None\n",
    "    txtlist = text.split()\n",
    "    if len(txtlist) <2:\n",
    "#        print('txtlist is too short', len(txtlist), text)\n",
    "        return None\n",
    "    if txtlist[1] in ['hour', 'hours']:\n",
    "        return 1\n",
    "    if txtlist[1] in ['day', 'days']:\n",
    "        return int(txtlist[0])\n",
    "    if txtlist[1] in ['week', 'weeks']:\n",
    "        return int(txtlist[0])*7\n",
    "    if txtlist[1] in ['month', 'months']:\n",
    "        return int(txtlist[0])*30\n",
    "    if txtlist[1] in ['year', 'years']:\n",
    "        return int(txtlist[0])*365\n",
    "    return None\n",
    "\n",
    "convert_day('12 months ago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e33561",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_functions = [\n",
    "    google_news_search,\n",
    "    #scrape_yahoo_news\n",
    "    #yahoo_news_search, \n",
    "    bing_news_search,\n",
    "    #duckduckgo_news_search\n",
    "]\n",
    "search_engine = ['Google', \n",
    "                 #'Yahoo', \n",
    "                 'Bing',\n",
    "                 #'DuckDuckGo'\n",
    "                ]\n",
    "\n",
    "#Google\n",
    "#search_results = dict()\n",
    "#search_results = [{'position' : 1, 'title': 'title', 'date': '20240621', 'link': 'http://google.com'}]\n",
    "#queries = ['query1', 'query 2']\n",
    "for indq, query in queries.iterrows():\n",
    "    for i in range(len(search_functions)):\n",
    "        # Initialize numbers and dates data row with query and search engine\n",
    "        num_dat_row = [query['Query'], search_engine[i]]\n",
    "        \n",
    "        # Do the search and only get top 20 \n",
    "        search_results = search_functions[i](query['Query'])\n",
    "        search_results = search_results[:min(20, len(search_results))]\n",
    "        \n",
    "        # Append  the number of articles to the num_dat_row\n",
    "        num_dat_row.append(len(search_results))\n",
    "        dates = []\n",
    "        days = []\n",
    "    \n",
    "        for article in search_results:\n",
    "            # search_data is a new data for the data frame search_results_articles\n",
    "            # 'Engine', 'Position', 'Title', 'Dates', 'Link', 'Content'\n",
    "            search_data = [\n",
    "                query['Query'],\n",
    "                search_engine[i],\n",
    "                article['title'],\n",
    "                article['date'],\n",
    "                article['link']\n",
    "            ]\n",
    "            search_results_articles.loc[len(search_results_articles)] = search_data\n",
    "            dates.append(search_data[3].strip())\n",
    "            days.append(convert_day(search_data[3].strip()))\n",
    "        # Dates and days information for the num_dat_rowx\n",
    "        num_dat_row.append(dates)\n",
    "        num_dat_row.append(days)\n",
    "        \n",
    "        # Add the num_dat_row to the data frame numbers_and_dates\n",
    "        numbers_and_dates.loc[len(numbers_and_dates)] = num_dat_row\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e18c42",
   "metadata": {},
   "source": [
    "### Yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17232183",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### For yahoo..\n",
    "# To count the number of articles\n",
    "def count_result(search_results):\n",
    "    count = 0\n",
    "    for index, result in enumerate(search_results, start=1):\n",
    "        count += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c0474da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vessel caught misreporting catch amount 0\n",
      "Vessel caught falsifying fishing logs 0\n",
      "Vessel caught with incorrect catch reports 6\n",
      "Vessel caught underreporting catch in North Atlantic 0\n",
      "Vessel caught misreporting haddock catch 0\n",
      "Vessel caught with inaccurate fish size records 0\n",
      "Vessel caught underreporting catch near protected area 0\n",
      "Vessel caught misreporting tuna catch quantities 0\n",
      "Vessel caught with unrecorded fish species 0\n",
      "Vessel caught bypassing quota system 0\n"
     ]
    }
   ],
   "source": [
    "######### Yahoo \n",
    "for indq, query in queries.iterrows():\n",
    "        # Initialize numbers and dates data row with query and search engine\n",
    "        num_dat_row = [query['Query'], 'Yahoo']\n",
    "        \n",
    "        # Do the search and only get top 20 \n",
    "        search_results = scrape_yahoo_news(query['Query'])\n",
    "        \n",
    "        # Append  the number of articles to the num_dat_row\n",
    "        count = count_result(search_results)\n",
    "        print(query['Query'],count)\n",
    "        num_dat_row.append(count)\n",
    "        dates = []\n",
    "        days = []\n",
    "    \n",
    "        for index, article in enumerate(search_results, start=1):\n",
    "            # search_data is a new data for the data frame search_results_articles\n",
    "            # 'Engine', 'Position', 'Title', 'Dates', 'Link', 'Content'\n",
    "            search_data = [\n",
    "                query['Query'],\n",
    "                'Yahoo',\n",
    "                article['title'],\n",
    "                article['date'],\n",
    "                article['link']\n",
    "            ]\n",
    "            search_results_articles.loc[len(search_results_articles)] = search_data\n",
    "            dates.append(search_data[3].strip())\n",
    "            days.append(convert_day(search_data[3].strip()))\n",
    "        # Dates and days information for the num_dat_row\n",
    "        num_dat_row.append(dates)\n",
    "        num_dat_row.append(days)\n",
    "        \n",
    "        # Add the num_dat_row to the data frame numbers_and_dates\n",
    "        numbers_and_dates.loc[len(numbers_and_dates)] = num_dat_row\n",
    "\n",
    "\n",
    "    \n",
    "#print(search_results_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84af8ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Query  Engine  results  \\\n",
      "0             Vessel caught misreporting catch amount  Google       20   \n",
      "1             Vessel caught misreporting catch amount    Bing        3   \n",
      "2               Vessel caught falsifying fishing logs  Google       20   \n",
      "3               Vessel caught falsifying fishing logs    Bing       14   \n",
      "4          Vessel caught with incorrect catch reports  Google       20   \n",
      "5          Vessel caught with incorrect catch reports    Bing       14   \n",
      "6   Vessel caught underreporting catch in North At...  Google       12   \n",
      "7   Vessel caught underreporting catch in North At...    Bing       14   \n",
      "8            Vessel caught misreporting haddock catch  Google        2   \n",
      "9            Vessel caught misreporting haddock catch    Bing       14   \n",
      "10    Vessel caught with inaccurate fish size records  Google       20   \n",
      "11    Vessel caught with inaccurate fish size records    Bing       14   \n",
      "12  Vessel caught underreporting catch near protec...  Google       20   \n",
      "13  Vessel caught underreporting catch near protec...    Bing       14   \n",
      "14   Vessel caught misreporting tuna catch quantities  Google       12   \n",
      "15   Vessel caught misreporting tuna catch quantities    Bing       14   \n",
      "16         Vessel caught with unrecorded fish species  Google       20   \n",
      "17         Vessel caught with unrecorded fish species    Bing       14   \n",
      "18               Vessel caught bypassing quota system  Google        5   \n",
      "19               Vessel caught bypassing quota system    Bing       14   \n",
      "\n",
      "                                                dates  \\\n",
      "0   [1 week ago, 1 month ago, 1 month ago, Oct 31,...   \n",
      "1                                      [10d, 1d, 10d]   \n",
      "2   [Mar 20, 2024, Oct 4, 2023, Mar 15, 2024, Feb ...   \n",
      "3   [26d, 3d, 3d, 29d, 5d, 4d, 7mon, 3mon, 11d, 7m...   \n",
      "4   [Mar 23, 2024, Oct 9, 2023, Jan 2, 2024, 2 wee...   \n",
      "5   [9d, 4d, 4d, 2d, 4d, 3d, 10d, 4d, 11d, 4d, 9d,...   \n",
      "6   [1 week ago, Mar 15, 2024, May 24, 2023, Sep 2...   \n",
      "7   [17d, 11d, 7d, 24d, 3d, 1mon, 4d, 4d, 1mon, 10...   \n",
      "8                         [Oct 9, 2020, Sep 28, 2022]   \n",
      "9   [3d, 3y, 4y, 4d, 3d, 7mon, 4mon, 1mon, 11d, 27...   \n",
      "10  [2 weeks ago, Oct 12, 2023, Aug 23, 2023, Feb ...   \n",
      "11  [4d, 2y, 26d, 5d, 5mon, 20d, 2y, 12d, 3y, 5y, ...   \n",
      "12  [1 week ago, Mar 1, 2024, Apr 2, 2024, Aug 16,...   \n",
      "13  [6d, 4d, 3d, 18d, 3d, 28d, 4d, 1y, 28d, 6d, 1y...   \n",
      "14  [Oct 11, 2021, Jan 3, 2019, Jun 14, 2021, Sep ...   \n",
      "15  [1y, 6y, 8d, 19d, 21d, 2y, 11d, 4mon, 1mon, 18...   \n",
      "16  [1 month ago, Apr 10, 2024, 3 weeks ago, 1 mon...   \n",
      "17  [2y, 22d, 6d, 14d, 10d, 3d, 1mon, 18d, 1mon, 1...   \n",
      "18  [Jul 17, 2023, Jun 13, 2010, May 9, 2016, Nov ...   \n",
      "19  [10mon, 2y, 1y, 12d, 3d, 16d, 7d, 3y, 21d, 2y,...   \n",
      "\n",
      "                                                 days  \n",
      "0   [7, 30, 30, 249, 346, 103, 254, 297, 901, 999,...  \n",
      "1                                         [10, 1, 10]  \n",
      "2   [108, 276, 113, 135, 283, 310, 309, 222, 317, ...  \n",
      "3   [26, 3, 3, 29, 5, 4, 210, 90, 11, 210, 5, 30, ...  \n",
      "4   [105, 271, 186, 14, 242, 103, 256, 250, 326, 2...  \n",
      "5        [9, 4, 4, 2, 4, 3, 10, 4, 11, 4, 9, 3, 4, 4]  \n",
      "6   [7, 113, 409, 649, 2328, 3090, 3806, 478, 2496...  \n",
      "7   [17, 11, 7, 24, 3, 30, 4, 4, 30, 300, 4, 30, 3...  \n",
      "8                                         [1366, 647]  \n",
      "9   [3, 1095, 1460, 4, 3, 210, 120, 30, 11, 27, 26...  \n",
      "10  [14, 268, 318, 519, 999, 884, 568, 2545, 393, ...  \n",
      "11  [4, 730, 26, 5, 150, 20, 730, 12, 1095, 1825, ...  \n",
      "12  [7, 127, 95, 325, 84, 3657, 613, 3432, 3966, 1...  \n",
      "13  [6, 4, 3, 18, 3, 28, 4, 365, 28, 6, 365, 6, 26...  \n",
      "14  [999, 2011, 1118, 2839, 884, 4987, 1351, 4495,...  \n",
      "15  [365, 2190, 8, 19, 21, 730, 11, 120, 30, 18, 1...  \n",
      "16  [30, 87, 21, 30, 264, 348, 243, 395, 381, 218,...  \n",
      "17  [730, 22, 6, 14, 10, 3, 30, 18, 30, 330, 330, ...  \n",
      "18                      [355, 5137, 2980, 1691, 2970]  \n",
      "19  [300, 730, 365, 12, 3, 16, 7, 1095, 21, 730, 2...  \n"
     ]
    }
   ],
   "source": [
    "print(numbers_and_dates.head(20))\n",
    "#search_results_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c781eb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Query, Engine, results, dates, days]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(numbers_and_dates.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e3ce8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2a2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e8f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25a6bc4d",
   "metadata": {},
   "source": [
    "## Export the data (excel file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93560e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been saved to output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "####### Have to have numberes_and_dates as a pandas data frame\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "numbers_and_dates.to_excel('numbers_and_dates.xlsx', index=False)\n",
    "\n",
    "print(\"DataFrame has been saved to output.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f8f610ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been saved to output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "######## Have to have search_results_articles as a pandas data frame\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "search_results_articles.to_excel('search_results_articles.xlsx', index=False)\n",
    "\n",
    "print(\"DataFrame has been saved to output.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7c8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
