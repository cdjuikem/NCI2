{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eed92d77",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "bf945c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c581a663",
   "metadata": {},
   "source": [
    "### 1. Import queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "cf90adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Query\n",
      "0            Vessel caught misreporting catch amount\n",
      "1              Vessel caught falsifying fishing logs\n",
      "2         Vessel caught with incorrect catch reports\n",
      "3  Vessel caught underreporting catch in North At...\n",
      "4           Vessel caught misreporting haddock catch\n",
      "5    Vessel caught with inaccurate fish size records\n",
      "6  Vessel caught underreporting catch near protec...\n",
      "7   Vessel caught misreporting tuna catch quantities\n",
      "8         Vessel caught with unrecorded fish species\n",
      "9               Vessel caught bypassing quota system\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the excel file\n",
    "excel_data = pd.read_excel('PIMS Sample Prompts.xlsx')\n",
    "\n",
    "queries = []\n",
    "for index, row in excel_data.iterrows():\n",
    "    # Process each row\n",
    "    queries.append(row['Prompt'])\n",
    "    \n",
    "queries = queries[:10]\n",
    "queries = pd.DataFrame(queries, columns = ['Query'])\n",
    "print(queries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6d5945f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vessel caught misreporting catch amount\n",
      "Vessel caught falsifying fishing logs\n",
      "Vessel caught with incorrect catch reports\n",
      "Vessel caught underreporting catch in North Atlantic\n",
      "Vessel caught misreporting haddock catch\n",
      "Vessel caught with inaccurate fish size records\n",
      "Vessel caught underreporting catch near protected area\n",
      "Vessel caught misreporting tuna catch quantities\n",
      "Vessel caught with unrecorded fish species\n",
      "Vessel caught bypassing quota system\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f5990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "168fa669",
   "metadata": {},
   "source": [
    "### 2. Data frame initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "237529d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Query, Engine, results, dates, days]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "numbers_and_dates = pd.DataFrame(columns = [\n",
    "    'Query', 'Engine',\n",
    "    'results', 'dates', 'days'\n",
    "])\n",
    "\n",
    "search_results_articles = pd.DataFrame(columns = ['Query', 'Engine','Title', 'Dates', 'Link'])\n",
    "print(numbers_and_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5472d69c",
   "metadata": {},
   "source": [
    "### 3. Google, Yahoo, Bing news search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f4785520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi import GoogleSearch\n",
    "# API Scrap functions\n",
    "\n",
    "def google_news_search(query, location = 'Canada'):\n",
    "    params = {\n",
    "        \"api_key\": \"7020efc655aafd1998bfad82b8f96fee27be3cdb26c1bb67909ba7042c56ebd1\",\n",
    "        \"q\": query,\n",
    "        \"tbm\": \"nws\",\n",
    "        \"location\": location,\n",
    "        \"num\": \"20\"\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    news_results = results[\"news_results\"]\n",
    "    return news_results\n",
    "\n",
    "def bing_news_search(query, location = \"CA\"):\n",
    "    params = {\n",
    "      \"api_key\": \"7020efc655aafd1998bfad82b8f96fee27be3cdb26c1bb67909ba7042c56ebd1\",\n",
    "      \"engine\": \"bing_news\",\n",
    "      \"q\": query,\n",
    "      \"cc\": location,\n",
    "      \"count\": \"20\"\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "\n",
    "    news_results = results[\"organic_results\"]\n",
    "    return news_results\n",
    "\n",
    "    \n",
    "def duckduckgo_news_search(query, location = \"ca-en\"):\n",
    "    params = {\n",
    "        \"engine\": \"duckduckgo\",\n",
    "        \"q\": query,\n",
    "        \"kl\": location,\n",
    "        \"tbm\": \"nws\",\n",
    "        #\"api_key\": \"7020efc655aafd1998bfad82b8f96fee27be3cdb26c1bb67909ba7042c56ebd1\"\n",
    "    }\n",
    "\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    print(results)\n",
    "#    news_results = results[\"news_results\"]\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "#duckduckgo_news_search(\"vessel underreport\")\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec8cd03",
   "metadata": {},
   "source": [
    "### 4. Search and scrap the results (title, dates, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3f8120d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def convert_day(text):\n",
    "    if None:\n",
    "        return None\n",
    "    pattern1 = r'^\\d{4}-\\d{2}-\\d{2}$'\n",
    "    pattern2 = r'\\b\\d+[dwmy]\\b'\n",
    "    pattern3 = r'^\\d{2}/\\d{2}/\\d{4}$'\n",
    "    pattern4 = r'(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s+\\d{1,2},\\s+\\d{4}'\n",
    "    \n",
    "    if re.match(pattern1, text):\n",
    "        date = datetime.strptime(text, \"%Y-%M-%d\").date()\n",
    "        today = datetime.combine(date.today(), datetime.min.time())\n",
    "        days = str(today - date).days\n",
    "        return int(days[0])\n",
    "    pattern2match = re.findall(pattern2, text)\n",
    "    if pattern2match:\n",
    "        text = pattern2match[0]\n",
    "        if text[len(text)-1] == 'd':\n",
    "            return int(text[:len(text)-1])\n",
    "        if text[len(text)-1] == 'w':\n",
    "            return int(text[:len(text)-1])*7\n",
    "        if text[len(text)-1] == 'm' or 'n':\n",
    "            return int(text[:len(text)-1])*30\n",
    "        if text[len(text)-1] == 'y':\n",
    "            return int(text[:len(text)-1])*365        \n",
    "\n",
    "    pattern3match = re.match(pattern3, text)\n",
    "    if pattern3match:\n",
    "        date_format = \"%m/%d/%Y\"\n",
    "        try:\n",
    "            # Parse the input date string into a datetime object\n",
    "            given_date = datetime.strptime(text, date_format).date()\n",
    "            # Get today's date\n",
    "            today = date.today()\n",
    "            # Calculate the difference in days\n",
    "            days_difference = (today - given_date).days\n",
    "            return int(days_difference)\n",
    "        except ValueError:\n",
    "            # Handle invalid date format or other errors\n",
    "            return None\n",
    "        \n",
    "    pattern4match = re.match(pattern4, text)\n",
    "    if pattern4match:\n",
    "        date_format = '%b %d, %Y'\n",
    "        try:\n",
    "            # Parse the input date string into a datetime object\n",
    "            given_date = datetime.strptime(text, date_format).date()\n",
    "            # Get today's date\n",
    "            today = datetime.now().date()\n",
    "            # Calculate the difference in days\n",
    "            days_difference = (today - given_date).days\n",
    "            return int(days_difference)\n",
    "\n",
    "        except ValueError:\n",
    "            # Handle invalid date format or other errors\n",
    "            return None\n",
    "    txtlist = text.split()\n",
    "    if len(txtlist) <2:\n",
    "        return None\n",
    "    if txtlist[1] in ['hour', 'hours']:\n",
    "        return 1\n",
    "    if txtlist[1] in ['day', 'days']:\n",
    "        return int(txtlist[0])\n",
    "    if txtlist[1] in ['week', 'weeks']:\n",
    "        return int(txtlist[0])*7\n",
    "    if txtlist[1] in ['month', 'months']:\n",
    "        return int(txtlist[0])*30\n",
    "    if txtlist[1] in ['year', 'years']:\n",
    "        return int(txtlist[0])*365\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "73e33561",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_functions = [\n",
    "    google_news_search,\n",
    "    #scrape_yahoo_news\n",
    "    #yahoo_news_search, \n",
    "    bing_news_search,\n",
    "    #duckduckgo_news_search\n",
    "]\n",
    "search_engine = ['Google', \n",
    "                 #'Yahoo', \n",
    "                 'Bing',\n",
    "                 #'DuckDuckGo'\n",
    "                ]\n",
    "\n",
    "#Google\n",
    "#search_results = dict()\n",
    "#search_results = [{'position' : 1, 'title': 'title', 'date': '20240621', 'link': 'http://google.com'}]\n",
    "#queries = ['query1', 'query 2']\n",
    "for indq, query in queries.iterrows():\n",
    "    for i in range(len(search_functions)):\n",
    "        # Initialize numbers and dates data row with query and search engine\n",
    "        num_dat_row = [query['Query'], search_engine[i]]\n",
    "        \n",
    "        # Do the search and only get top 20 \n",
    "        search_results = search_functions[i](query)\n",
    "        search_results = search_results[:min(20, len(search_results))]\n",
    "        \n",
    "        # Append  the number of articles to the num_dat_row\n",
    "        num_dat_row.append(len(search_results))\n",
    "        dates = []\n",
    "        days = []\n",
    "    \n",
    "        for article in search_results:\n",
    "            # search_data is a new data for the data frame search_results_articles\n",
    "            # 'Engine', 'Position', 'Title', 'Dates', 'Link', 'Content'\n",
    "            search_data = [\n",
    "                query['Query'],\n",
    "                search_engine[i],\n",
    "                article['title'],\n",
    "                article['date'],\n",
    "                article['link']\n",
    "            ]\n",
    "            search_results_articles.loc[len(search_results_articles)] = search_data\n",
    "            dates.append(search_data[3])\n",
    "            days.append(convert_day(search_data[3]))\n",
    "        # Dates and days information for the num_dat_row\n",
    "        num_dat_row.append(dates)\n",
    "        num_dat_row.append(days)\n",
    "        \n",
    "        # Add the num_dat_row to the data frame numbers_and_dates\n",
    "        numbers_and_dates.loc[len(numbers_and_dates)] = num_dat_row\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e18c42",
   "metadata": {},
   "source": [
    "### Yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "17232183",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### For yahoo..\n",
    "# To count the number of articles\n",
    "def count_result(search_results):\n",
    "    count = 0\n",
    "    for index, result in enumerate(search_results, start=1):\n",
    "        count += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1c0474da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vessel caught misreporting catch amount 0\n",
      "Vessel caught falsifying fishing logs 0\n",
      "Vessel caught with incorrect catch reports 0\n",
      "Vessel caught underreporting catch in North Atlantic 0\n",
      "Vessel caught misreporting haddock catch 0\n",
      "Vessel caught with inaccurate fish size records 0\n",
      "Vessel caught underreporting catch near protected area 0\n",
      "Vessel caught misreporting tuna catch quantities 0\n",
      "Vessel caught with unrecorded fish species 0\n",
      "Vessel caught bypassing quota system 0\n"
     ]
    }
   ],
   "source": [
    "######### Yahoo \n",
    "for indq, query in queries.iterrows():\n",
    "        # Initialize numbers and dates data row with query and search engine\n",
    "        num_dat_row = [query['Query'], 'Yahoo']\n",
    "        \n",
    "        # Do the search and only get top 20 \n",
    "        search_results = scrape_yahoo_news(query)\n",
    "        \n",
    "        # Append  the number of articles to the num_dat_row\n",
    "        count = count_result(search_results)\n",
    "        print(query['Query'],count)\n",
    "        num_dat_row.append(count)\n",
    "        dates = []\n",
    "        days = []\n",
    "    \n",
    "        for index, article in enumerate(search_results, start=1):\n",
    "            # search_data is a new data for the data frame search_results_articles\n",
    "            # 'Engine', 'Position', 'Title', 'Dates', 'Link', 'Content'\n",
    "            search_data = [\n",
    "                query['Query'],\n",
    "                'Yahoo',\n",
    "                article['title'],\n",
    "                article['date'],\n",
    "                article['link']\n",
    "            ]\n",
    "            search_results_articles.loc[len(search_results_articles)] = search_data\n",
    "            dates.append(search_data[3])\n",
    "            days.append(convert_day(search_data[3]))\n",
    "        # Dates and days information for the num_dat_row\n",
    "        num_dat_row.append(dates)\n",
    "        num_dat_row.append(days)\n",
    "        \n",
    "        # Add the num_dat_row to the data frame numbers_and_dates\n",
    "        numbers_and_dates.loc[len(numbers_and_dates)] = num_dat_row\n",
    "\n",
    "\n",
    "    \n",
    "#print(search_results_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "84af8ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Engine</th>\n",
       "      <th>Title</th>\n",
       "      <th>Dates</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Query    Vessel caught with unrecorded fish sp...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>Vessels must slow down to save whale species f...</td>\n",
       "      <td>1y</td>\n",
       "      <td>https://www.glasgowtimes.co.uk/news/national/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Sea Shepherd Global</td>\n",
       "      <td>2 weeks ago</td>\n",
       "      <td>https://www.seashepherdglobal.org/latest-news/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Google</td>\n",
       "      <td>UK Government seizes post-Brexit freedoms for ...</td>\n",
       "      <td>Jul 17, 2023</td>\n",
       "      <td>https://thefishingdaily.com/latest-news/uk-gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Fish mogul indicted on 27 criminal counts | St...</td>\n",
       "      <td>May 9, 2016</td>\n",
       "      <td>https://www.salemnews.com/news/state_news/fish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Grounded: Rather than test new limits, fisherm...</td>\n",
       "      <td>Jun 13, 2010</td>\n",
       "      <td>https://www.southcoasttoday.com/story/news/201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Google</td>\n",
       "      <td>East Anglia group sets out long-term plan</td>\n",
       "      <td>Nov 19, 2019</td>\n",
       "      <td>https://fishingnews.co.uk/news/east-anglia-gro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>Vessel Monitoring System Market</td>\n",
       "      <td>2y</td>\n",
       "      <td>https://www.alliedmarketresearch.com/vessel-mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>Remote vessel communications system clinches AiP</td>\n",
       "      <td>2d</td>\n",
       "      <td>https://www.rivieramm.com/news-content-hub/new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>AI Targeting system trialled on NYK vessel</td>\n",
       "      <td>2y</td>\n",
       "      <td>https://www.seatrade-maritime.com/technology/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>Offshore Vessels News</td>\n",
       "      <td>8d</td>\n",
       "      <td>https://www.oedigital.com/vessels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>Bluefin tuna season to open tomorrow with 25t ...</td>\n",
       "      <td>6d</td>\n",
       "      <td>https://www.chronicle.gi/bluefin-tuna-season-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>The Peruvian Navy tests a new illegal vessel d...</td>\n",
       "      <td>15d</td>\n",
       "      <td>https://www.zona-militar.com/en/2024/06/06/the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>Coast Guard seizes $63m worth of cocaine after...</td>\n",
       "      <td>12d</td>\n",
       "      <td>https://www.dailymail.co.uk/news/article-13510...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>Circulatory system: Blood vessels</td>\n",
       "      <td>9d</td>\n",
       "      <td>https://www.dailymail.co.uk/health/article-109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>QLABPro Close Vessel Microwave Digestion Syste...</td>\n",
       "      <td>7d</td>\n",
       "      <td>https://www.news-medical.net/QLABPro-Close-Ves...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>Redistributing medical resources for a bypass ...</td>\n",
       "      <td>1d</td>\n",
       "      <td>https://jnis.bmj.com/content/12/1/98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>2 dead, 3 missing after vessel catches fire in...</td>\n",
       "      <td>15d</td>\n",
       "      <td>https://www.punjabnewsexpress.com/world/news/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>Peruvian authorities implement “laughable” fin...</td>\n",
       "      <td>23d</td>\n",
       "      <td>https://www.seafoodsource.com/news/supply-trad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>UK Navy says vessel hit by projectile in Gulf ...</td>\n",
       "      <td>12d</td>\n",
       "      <td>https://www.thehansindia.com/news/internationa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>Query    Vessel caught bypassing quota system\n",
       "...</td>\n",
       "      <td>Bing</td>\n",
       "      <td>Eleven dead and over 60 missing as migrant boa...</td>\n",
       "      <td>3d</td>\n",
       "      <td>https://ca.news.yahoo.com/eleven-dead-over-60-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Query  Engine  \\\n",
       "269  Query    Vessel caught with unrecorded fish sp...    Bing   \n",
       "270  Query    Vessel caught bypassing quota system\n",
       "...  Google   \n",
       "271  Query    Vessel caught bypassing quota system\n",
       "...  Google   \n",
       "272  Query    Vessel caught bypassing quota system\n",
       "...  Google   \n",
       "273  Query    Vessel caught bypassing quota system\n",
       "...  Google   \n",
       "274  Query    Vessel caught bypassing quota system\n",
       "...  Google   \n",
       "275  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "276  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "277  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "278  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "279  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "280  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "281  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "282  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "283  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "284  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "285  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "286  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "287  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "288  Query    Vessel caught bypassing quota system\n",
       "...    Bing   \n",
       "\n",
       "                                                 Title         Dates  \\\n",
       "269  Vessels must slow down to save whale species f...            1y   \n",
       "270                                Sea Shepherd Global   2 weeks ago   \n",
       "271  UK Government seizes post-Brexit freedoms for ...  Jul 17, 2023   \n",
       "272  Fish mogul indicted on 27 criminal counts | St...   May 9, 2016   \n",
       "273  Grounded: Rather than test new limits, fisherm...  Jun 13, 2010   \n",
       "274          East Anglia group sets out long-term plan  Nov 19, 2019   \n",
       "275                    Vessel Monitoring System Market            2y   \n",
       "276   Remote vessel communications system clinches AiP            2d   \n",
       "277         AI Targeting system trialled on NYK vessel            2y   \n",
       "278                              Offshore Vessels News            8d   \n",
       "279  Bluefin tuna season to open tomorrow with 25t ...            6d   \n",
       "280  The Peruvian Navy tests a new illegal vessel d...           15d   \n",
       "281  Coast Guard seizes $63m worth of cocaine after...           12d   \n",
       "282                  Circulatory system: Blood vessels            9d   \n",
       "283  QLABPro Close Vessel Microwave Digestion Syste...            7d   \n",
       "284  Redistributing medical resources for a bypass ...            1d   \n",
       "285  2 dead, 3 missing after vessel catches fire in...           15d   \n",
       "286  Peruvian authorities implement “laughable” fin...           23d   \n",
       "287  UK Navy says vessel hit by projectile in Gulf ...           12d   \n",
       "288  Eleven dead and over 60 missing as migrant boa...            3d   \n",
       "\n",
       "                                                  Link  \n",
       "269  https://www.glasgowtimes.co.uk/news/national/2...  \n",
       "270  https://www.seashepherdglobal.org/latest-news/...  \n",
       "271  https://thefishingdaily.com/latest-news/uk-gov...  \n",
       "272  https://www.salemnews.com/news/state_news/fish...  \n",
       "273  https://www.southcoasttoday.com/story/news/201...  \n",
       "274  https://fishingnews.co.uk/news/east-anglia-gro...  \n",
       "275  https://www.alliedmarketresearch.com/vessel-mo...  \n",
       "276  https://www.rivieramm.com/news-content-hub/new...  \n",
       "277  https://www.seatrade-maritime.com/technology/a...  \n",
       "278                  https://www.oedigital.com/vessels  \n",
       "279  https://www.chronicle.gi/bluefin-tuna-season-t...  \n",
       "280  https://www.zona-militar.com/en/2024/06/06/the...  \n",
       "281  https://www.dailymail.co.uk/news/article-13510...  \n",
       "282  https://www.dailymail.co.uk/health/article-109...  \n",
       "283  https://www.news-medical.net/QLABPro-Close-Ves...  \n",
       "284               https://jnis.bmj.com/content/12/1/98  \n",
       "285  https://www.punjabnewsexpress.com/world/news/2...  \n",
       "286  https://www.seafoodsource.com/news/supply-trad...  \n",
       "287  https://www.thehansindia.com/news/internationa...  \n",
       "288  https://ca.news.yahoo.com/eleven-dead-over-60-...  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_and_dates.tail(20)\n",
    "search_results_articles.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c781eb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Query  Engine  results  \\\n",
      "0   Query    Vessel caught misreporting catch amou...  Google       20   \n",
      "1   Query    Vessel caught misreporting catch amou...   Yahoo        0   \n",
      "2   Query    Vessel caught misreporting catch amou...    Bing       14   \n",
      "3   Query    Vessel caught falsifying fishing logs...  Google       20   \n",
      "4   Query    Vessel caught falsifying fishing logs...   Yahoo        0   \n",
      "5   Query    Vessel caught falsifying fishing logs...    Bing       14   \n",
      "6   Query    Vessel caught with incorrect catch re...  Google       20   \n",
      "7   Query    Vessel caught with incorrect catch re...   Yahoo        0   \n",
      "8   Query    Vessel caught with incorrect catch re...    Bing       12   \n",
      "9   Query    Vessel caught underreporting catch in...  Google       14   \n",
      "10  Query    Vessel caught underreporting catch in...   Yahoo        0   \n",
      "11  Query    Vessel caught underreporting catch in...    Bing       11   \n",
      "12  Query    Vessel caught misreporting haddock ca...  Google        2   \n",
      "13  Query    Vessel caught misreporting haddock ca...   Yahoo        0   \n",
      "14  Query    Vessel caught misreporting haddock ca...    Bing       14   \n",
      "15  Query    Vessel caught with inaccurate fish si...  Google       20   \n",
      "16  Query    Vessel caught with inaccurate fish si...   Yahoo        0   \n",
      "17  Query    Vessel caught with inaccurate fish si...    Bing       14   \n",
      "18  Query    Vessel caught underreporting catch ne...  Google       20   \n",
      "19  Query    Vessel caught underreporting catch ne...   Yahoo        0   \n",
      "20  Query    Vessel caught underreporting catch ne...    Bing       14   \n",
      "21  Query    Vessel caught misreporting tuna catch...  Google       13   \n",
      "22  Query    Vessel caught misreporting tuna catch...   Yahoo        0   \n",
      "23  Query    Vessel caught misreporting tuna catch...    Bing       14   \n",
      "24  Query    Vessel caught with unrecorded fish sp...  Google       20   \n",
      "25  Query    Vessel caught with unrecorded fish sp...   Yahoo        0   \n",
      "26  Query    Vessel caught with unrecorded fish sp...    Bing       14   \n",
      "27  Query    Vessel caught bypassing quota system\n",
      "...  Google        5   \n",
      "28  Query    Vessel caught bypassing quota system\n",
      "...   Yahoo        0   \n",
      "29  Query    Vessel caught bypassing quota system\n",
      "...    Bing       14   \n",
      "30            Vessel caught misreporting catch amount   Yahoo        0   \n",
      "31              Vessel caught falsifying fishing logs   Yahoo        0   \n",
      "32         Vessel caught with incorrect catch reports   Yahoo        0   \n",
      "33  Vessel caught underreporting catch in North At...   Yahoo        0   \n",
      "34           Vessel caught misreporting haddock catch   Yahoo        0   \n",
      "35    Vessel caught with inaccurate fish size records   Yahoo        0   \n",
      "36  Vessel caught underreporting catch near protec...   Yahoo        0   \n",
      "37   Vessel caught misreporting tuna catch quantities   Yahoo        0   \n",
      "38         Vessel caught with unrecorded fish species   Yahoo        0   \n",
      "39               Vessel caught bypassing quota system   Yahoo        0   \n",
      "\n",
      "                                                dates  \\\n",
      "0   [2 weeks ago, Oct 31, 2023, 1 month ago, Jul 2...   \n",
      "1                                                  []   \n",
      "2   [13d, 12d, 12d, 3d, 13d, 12d, 8d, 8d, 13d, 12d...   \n",
      "3   [قبل أسبوع واحد, ٢٠‏/٠٣‏/٢٠٢٤, ٠٤‏/١٠‏/٢٠٢٣, ٢...   \n",
      "4                                                  []   \n",
      "5   [17d, 11d, 2d, 23d, 2mon, 3d, 1mon, 14d, 1mon,...   \n",
      "6   [3 days ago, Mar 23, 2024, Oct 9, 2023, Jan 2,...   \n",
      "7                                                  []   \n",
      "8   [2d, 2d, 12d, 3d, 5d, 8d, 3d, 12d, 12d, 12d, 1...   \n",
      "9   [May 24, 2023, Sep 26, 2022, Jan 19, 2016, May...   \n",
      "10                                                 []   \n",
      "11  [8h, 1mon, 3d, 12d, 9d, 8d, 22d, 15d, 3d, 12d,...   \n",
      "12                        [Oct 9, 2020, Sep 28, 2022]   \n",
      "13                                                 []   \n",
      "14  [1mon, 3d, 23d, 4mon, 2mon, 4y, 7mon, 15d, 14y...   \n",
      "15  [3 days ago, Aug 23, 2023, Nov 6, 2023, Feb 3,...   \n",
      "16                                                 []   \n",
      "17  [6y, 2y, 4d, 3d, 14d, 1y, 3y, 3d, 2y, 1mon, 4m...   \n",
      "18  [Mar 1, 2024, Apr 2, 2024, 1 month ago, Apr 13...   \n",
      "19                                                 []   \n",
      "20  [4d, 1mon, 19d, 15d, 1mon, 2mon, 23d, 17d, 12d...   \n",
      "21  [Oct 11, 2021, Jan 3, 2019, Jun 14, 2021, Feb ...   \n",
      "22                                                 []   \n",
      "23  [2mon, 1y, 6d, 4d, 6y, 3d, 2y, 3d, 2y, 2y, 7d,...   \n",
      "24  [1 week ago, Jul 24, 2023, Nov 6, 2023, Apr 10...   \n",
      "25                                                 []   \n",
      "26  [2y, 2y, 2y, 3d, 3d, 12d, 12d, 27d, 1mon, 15d,...   \n",
      "27  [2 weeks ago, Jul 17, 2023, May 9, 2016, Jun 1...   \n",
      "28                                                 []   \n",
      "29  [2y, 2d, 2y, 8d, 6d, 15d, 12d, 9d, 7d, 1d, 15d...   \n",
      "30                                                 []   \n",
      "31                                                 []   \n",
      "32                                                 []   \n",
      "33                                                 []   \n",
      "34                                                 []   \n",
      "35                                                 []   \n",
      "36                                                 []   \n",
      "37                                                 []   \n",
      "38                                                 []   \n",
      "39                                                 []   \n",
      "\n",
      "                                                 days  \n",
      "0   [14, 234, 30, 331, 88, 239, 282, 69, 886, 984,...  \n",
      "1                                                  []  \n",
      "2   [13, 12, 12, 3, 13, 12, 8, 8, 13, 12, 8, 12, 1...  \n",
      "3   [None, None, None, None, None, None, None, Non...  \n",
      "4                                                  []  \n",
      "5   [17, 11, 2, 23, None, 3, None, 14, None, 15, N...  \n",
      "6   [3, 90, 256, 171, 227, 241, 331, 351, 288, 288...  \n",
      "7                                                  []  \n",
      "8          [2, 2, 12, 3, 5, 8, 3, 12, 12, 12, 12, 12]  \n",
      "9   [394, 634, 3076, 408, 3075, 3791, 463, 2481, 1...  \n",
      "10                                                 []  \n",
      "11       [None, None, 3, 12, 9, 8, 22, 15, 3, 12, 12]  \n",
      "12                                        [1351, 632]  \n",
      "13                                                 []  \n",
      "14  [None, 3, 23, None, None, 120, None, 15, 420, ...  \n",
      "15  [3, 303, 228, 504, 984, 413, 441, 4412, 1138, ...  \n",
      "16                                                 []  \n",
      "17  [180, 60, 4, 3, 14, 30, 90, 3, 60, None, None,...  \n",
      "18  [112, 80, 30, 69, 3642, 598, 3417, 1032, 3951,...  \n",
      "19                                                 []  \n",
      "20  [4, None, 19, 15, None, None, 23, 17, 12, 15, ...  \n",
      "21  [984, 1996, 1103, 869, 4972, 2698, 1336, 4480,...  \n",
      "22                                                 []  \n",
      "23  [None, 30, 6, 4, 180, 3, 60, 3, 60, 60, 7, 6, ...  \n",
      "24  [7, 333, 228, 72, 380, 366, 203, 1485, 253, 10...  \n",
      "25                                                 []  \n",
      "26  [60, 60, 60, 3, 3, 12, 12, 27, None, 15, 8, 6,...  \n",
      "27                        [14, 340, 2965, 5122, 1676]  \n",
      "28                                                 []  \n",
      "29  [60, 2, 60, 8, 6, 15, 12, 9, 7, 1, 15, 23, 12, 3]  \n",
      "30                                                 []  \n",
      "31                                                 []  \n",
      "32                                                 []  \n",
      "33                                                 []  \n",
      "34                                                 []  \n",
      "35                                                 []  \n",
      "36                                                 []  \n",
      "37                                                 []  \n",
      "38                                                 []  \n",
      "39                                                 []  \n"
     ]
    }
   ],
   "source": [
    "print(numbers_and_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e3ce8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3c2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e2a2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e8f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25a6bc4d",
   "metadata": {},
   "source": [
    "## Export the data (excel file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "93560e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been saved to output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "####### Have to have numberes_and_dates as a pandas data frame\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "numbers_and_dates.to_excel('numbers_and_dates.xlsx', index=False)\n",
    "\n",
    "print(\"DataFrame has been saved to output.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f8f610ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has been saved to output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "######## Have to have search_results_articles as a pandas data frame\n",
    "#df = pd.DataFrame(data)\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "search_results_articles.to_excel('search_results_articles.xlsx', index=False)\n",
    "\n",
    "print(\"DataFrame has been saved to output.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7c8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
