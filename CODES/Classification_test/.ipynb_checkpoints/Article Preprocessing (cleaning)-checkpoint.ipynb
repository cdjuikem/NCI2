{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55909794",
   "metadata": {},
   "source": [
    "### Import the excel file with articles and contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7efe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9965ca2c",
   "metadata": {},
   "source": [
    "#### Import the data (title, content of articles) from the excel file scraped_contents.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2edf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the excel file\n",
    "excel_data = pd.read_excel('scraped_contents.xlsx')\n",
    "\n",
    "new_data = excel_data[['Query', 'Engine','Content']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b4bb4",
   "metadata": {},
   "source": [
    "### Identify rows with missing contents and drop them from the data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ac83ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the indices of rows with missing content [42, 75, 291]\n"
     ]
    }
   ],
   "source": [
    "missing_content_ind = []\n",
    "for ind, row in excel_data.iterrows():    \n",
    "    if (type(row['Content']) != str):\n",
    "        \n",
    "        # Collecting missing content rows\n",
    "        missing_content_ind.append(ind)\n",
    "    else:\n",
    "        # For all rows with content (not missing),\n",
    "        # concatenate title and content together and save it as 'Content' in new_data \n",
    "        title_and_content = row['Title'] +  row['Content']  \n",
    "        new_data.at[ind, 'Content'] = title_and_content \n",
    "        \n",
    "print(\"Here are the indices of rows with missing content\", missing_content_ind)\n",
    "\n",
    "num_rows = len(new_data)\n",
    "\n",
    "#### drop the missing content rows\n",
    "filtered_data = new_data.drop(missing_content_ind)\n",
    "filtered_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae9d99",
   "metadata": {},
   "source": [
    "### Cleaning the content and title (lower case, no special characters, verb cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0396f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind 0\n",
      "ind 1\n",
      "ind 2\n",
      "ind 3\n",
      "ind 4\n",
      "ind 5\n",
      "ind 6\n",
      "ind 7\n",
      "ind 8\n",
      "ind 9\n",
      "ind 10\n",
      "ind 11\n",
      "ind 12\n",
      "ind 13\n",
      "ind 14\n",
      "ind 15\n",
      "ind 16\n",
      "ind 17\n",
      "ind 18\n",
      "ind 19\n",
      "ind 20\n",
      "ind 21\n",
      "ind 22\n",
      "ind 23\n",
      "ind 24\n",
      "ind 25\n",
      "ind 26\n",
      "ind 27\n",
      "ind 28\n",
      "ind 29\n",
      "ind 30\n",
      "ind 31\n",
      "ind 32\n",
      "ind 33\n",
      "ind 34\n",
      "ind 35\n",
      "ind 36\n",
      "ind 37\n",
      "ind 38\n",
      "ind 39\n",
      "ind 40\n",
      "ind 41\n",
      "ind 42\n",
      "ind 43\n",
      "ind 44\n",
      "ind 45\n",
      "ind 46\n",
      "ind 47\n",
      "ind 48\n",
      "ind 49\n",
      "ind 50\n",
      "ind 51\n",
      "ind 52\n",
      "ind 53\n",
      "ind 54\n",
      "ind 55\n",
      "ind 56\n",
      "ind 57\n",
      "ind 58\n",
      "ind 59\n",
      "ind 60\n",
      "ind 61\n",
      "ind 62\n",
      "ind 63\n",
      "ind 64\n",
      "ind 65\n",
      "ind 66\n",
      "ind 67\n",
      "ind 68\n",
      "ind 69\n",
      "ind 70\n",
      "ind 71\n",
      "ind 72\n",
      "ind 73\n",
      "ind 74\n",
      "ind 75\n",
      "ind 76\n",
      "ind 77\n",
      "ind 78\n",
      "ind 79\n",
      "ind 80\n",
      "ind 81\n",
      "ind 82\n",
      "ind 83\n",
      "ind 84\n",
      "ind 85\n",
      "ind 86\n",
      "ind 87\n",
      "ind 88\n",
      "ind 89\n",
      "ind 90\n",
      "ind 91\n",
      "ind 92\n",
      "ind 93\n",
      "ind 94\n",
      "ind 95\n",
      "ind 96\n",
      "ind 97\n",
      "ind 98\n",
      "ind 99\n",
      "ind 100\n",
      "ind 101\n",
      "ind 102\n",
      "ind 103\n",
      "ind 104\n",
      "ind 105\n",
      "ind 106\n",
      "ind 107\n",
      "ind 108\n",
      "ind 109\n",
      "ind 110\n",
      "ind 111\n",
      "ind 112\n",
      "ind 113\n",
      "ind 114\n",
      "ind 115\n",
      "ind 116\n",
      "ind 117\n",
      "ind 118\n",
      "ind 119\n",
      "ind 120\n",
      "ind 121\n",
      "ind 122\n",
      "ind 123\n",
      "ind 124\n",
      "ind 125\n",
      "ind 126\n",
      "ind 127\n",
      "ind 128\n",
      "ind 129\n",
      "ind 130\n",
      "ind 131\n",
      "ind 132\n",
      "ind 133\n",
      "ind 134\n",
      "ind 135\n",
      "ind 136\n",
      "ind 137\n",
      "ind 138\n",
      "ind 139\n",
      "ind 140\n",
      "ind 141\n",
      "ind 142\n",
      "ind 143\n",
      "ind 144\n",
      "ind 145\n",
      "ind 146\n",
      "ind 147\n",
      "ind 148\n",
      "ind 149\n",
      "ind 150\n",
      "ind 151\n",
      "ind 152\n",
      "ind 153\n",
      "ind 154\n",
      "ind 155\n",
      "ind 156\n",
      "ind 157\n",
      "ind 158\n",
      "ind 159\n",
      "ind 160\n",
      "ind 161\n",
      "ind 162\n",
      "ind 163\n",
      "ind 164\n",
      "ind 165\n",
      "ind 166\n",
      "ind 167\n",
      "ind 168\n",
      "ind 169\n",
      "ind 170\n",
      "ind 171\n",
      "ind 172\n",
      "ind 173\n",
      "ind 174\n",
      "ind 175\n",
      "ind 176\n",
      "ind 177\n",
      "ind 178\n",
      "ind 179\n",
      "ind 180\n",
      "ind 181\n",
      "ind 182\n",
      "ind 183\n",
      "ind 184\n",
      "ind 185\n",
      "ind 186\n",
      "ind 187\n",
      "ind 188\n",
      "ind 189\n",
      "ind 190\n",
      "ind 191\n",
      "ind 192\n",
      "ind 193\n",
      "ind 194\n",
      "ind 195\n",
      "ind 196\n",
      "ind 197\n",
      "ind 198\n",
      "ind 199\n",
      "ind 200\n",
      "ind 201\n",
      "ind 202\n",
      "ind 203\n",
      "ind 204\n",
      "ind 205\n",
      "ind 206\n",
      "ind 207\n",
      "ind 208\n",
      "ind 209\n",
      "ind 210\n",
      "ind 211\n",
      "ind 212\n",
      "ind 213\n",
      "ind 214\n",
      "ind 215\n",
      "ind 216\n",
      "ind 217\n",
      "ind 218\n",
      "ind 219\n",
      "ind 220\n",
      "ind 221\n",
      "ind 222\n",
      "ind 223\n",
      "ind 224\n",
      "ind 225\n",
      "ind 226\n",
      "ind 227\n",
      "ind 228\n",
      "ind 229\n",
      "ind 230\n",
      "ind 231\n",
      "ind 232\n",
      "ind 233\n",
      "ind 234\n",
      "ind 235\n",
      "ind 236\n",
      "ind 237\n",
      "ind 238\n",
      "ind 239\n",
      "ind 240\n",
      "ind 241\n",
      "ind 242\n",
      "ind 243\n",
      "ind 244\n",
      "ind 245\n",
      "ind 246\n",
      "ind 247\n",
      "ind 248\n",
      "ind 249\n",
      "ind 250\n",
      "ind 251\n",
      "ind 252\n",
      "ind 253\n",
      "ind 254\n",
      "ind 255\n",
      "ind 256\n",
      "ind 257\n",
      "ind 258\n",
      "ind 259\n",
      "ind 260\n",
      "ind 261\n",
      "ind 262\n",
      "ind 263\n",
      "ind 264\n",
      "ind 265\n",
      "ind 266\n",
      "ind 267\n",
      "ind 268\n",
      "ind 269\n",
      "ind 270\n",
      "ind 271\n",
      "ind 272\n",
      "ind 273\n",
      "ind 274\n",
      "ind 275\n",
      "ind 276\n",
      "ind 277\n",
      "ind 278\n",
      "ind 279\n",
      "ind 280\n",
      "ind 281\n",
      "ind 282\n",
      "ind 283\n",
      "ind 284\n",
      "ind 285\n",
      "ind 286\n",
      "ind 287\n",
      "ind 288\n",
      "ind 289\n",
      "ind 290\n",
      "ind 291\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = filtered_data.copy()\n",
    "\n",
    "for ind, row in filtered_data.iterrows():\n",
    "    print(\"ind\", ind)\n",
    "    text = row['Content']\n",
    "    text = text_preprocess(text)\n",
    "    text = rep_word_text(text)\n",
    "    cleaned_data.iloc[ind]['Content'] = text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77038d16",
   "metadata": {},
   "source": [
    "### Save cleaned_data in a different excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b9a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Have to have search_results_articles as a pandas data frame\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "cleaned_data.to_excel('cleaned_for_classification.xlsx', index=False)\n",
    "\n",
    "print(\"DataFrame has been saved to output.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be736f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae13645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
