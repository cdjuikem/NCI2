{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1afe637a",
   "metadata": {},
   "source": [
    "# Meeting Notes\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887fdde",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> June 17 2024, Monday </font>\n",
    "\n",
    "### What to do:\n",
    "#### Main functions\n",
    "1. Synonym/derive form function (Hiva)\n",
    "2. Incorporate synonym/derive form function to relevance score function (Hiva)\n",
    "3. Test the relevance score function with relevant articles to ensure the function works as we intended (Clotilde)\n",
    "4. Think about how to handle less than 20 search results situation - not today\n",
    "    * For example: \n",
    "    * 2 result from Google and one of them relevant\n",
    "    * 3 result from Yahoo and one of them was relevant\n",
    "    * -> Then Google gives 50% relevant articles, Yahoo 33.3%. Which one is better?\n",
    "    * Some thoughts: <font color = 'red'> (Sumin) I think the number of results itself can be an indicator of the performance. </font>\n",
    "5. Information Evaluation function (Sumin) - working on correctly identifying country’s names\n",
    "6. Search for machine learning algorithm to determine the classification threshold\n",
    "    * Support Vector Machines\n",
    "        - Pros: \n",
    "        - Cons: \n",
    "    * Logistic Regression\n",
    "        - Pros:\n",
    "        - Cons:\n",
    "7. In what aspect can we recommend which engine is better than the others?\n",
    "    * Number of results\n",
    "    * Portion of relevant results among all results\n",
    "    * Amount of specific information\n",
    "\n",
    "\n",
    "#### Scraping issues\n",
    "1. Consider to use topic specific search engines\n",
    "    * https://maritimescrimes.com/\n",
    "    * https://maritime-executive.com/\n",
    "2. Use Google instead of Google News in scrap code (Sumin)\n",
    "3. Review scraping tool  using different browsers /  RSS - not today\n",
    "    * Maritime Executive authorization issue can be solved by RSS\n",
    "        https://medium.com/@darshipatel/web-scrapping-rss-feed-using-python-fb82370562b3\n",
    "    * Page with JavaScript cannot be scraped by Beautiful Soup\n",
    "        https://www.scrapingbee.com/blog/selenium-python/\n",
    "\n",
    "\n",
    "#### Report and Presentation\n",
    "1. Review previous works (Irushi)\n",
    "    * We have some references - add them to Overleaf (bibtex using MathSciNet?)\n",
    "        - Information Processing and Management (Gao, Shah, 2020) - slack\n",
    "        - Low-cost evaluation techniques for information retrieval systems: A review (Moghadasi, Ravana, Raman, 2013)\n",
    "        - A search engine model: Web Scraping, Natural Language Processing, and Pointwise Mutual Information (Almaraz-Rivera, 2020)\n",
    "        - Performance Evaluation of Selected Search Engines (Ajayi et al, 2014) -in our github\n",
    "    * Search for more if exists\n",
    "2. Slide draft (Irushi)\n",
    "    * Problem description\n",
    "    * Our approach / progress\n",
    "    * (Results) - let’s try to get them by Thursday!\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6fc1dc",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> June 14 2024, Friday </font>\n",
    "\n",
    "### What to do:\n",
    "* Make a list of (semi-manually) synonyms/related words for keywords in queries\n",
    "* Come up with a list of common relevant words in the queries such as “misreport”, “underreport”, “vessel”, “catch/fish”, “violation”, etc\n",
    "    - This is because our goal is to find incident reports rather than general articles about ocean crimes. (If the relevance score function can filter general articles, that’ll be great!)\n",
    "    - This list can be used to preprocess the text (See 3. For details) and evaluate the relevance score\n",
    "* Write a preprocessing function that maps a group of synonyms to one word\n",
    "    - For example, when we know {sea, ocean} is a set of synonyms,\n",
    "    - “In the sea, there are so many ocean animals.” can be processed as\n",
    "    - “In the sea, there are so many sea animals” or \n",
    "    - “In the ocean, there are so many ocean animals”.\n",
    "* How to extract information from articles (location/incident/names/fish species, etc)\n",
    "* (done) Fix the content scrap code\n",
    "* Check the references\n",
    "* Presentation slide (Thursday)\n",
    "    - Problem description\n",
    "    - Our approach\n",
    "    - Progress\n",
    "    - Plan \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995771d4",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> June 13, 2024, Thursday </font>\n",
    "### What we did:\n",
    "#### Variables:\n",
    "Details can be found here in this [link](https://docs.google.com/document/d/1HDImwWFsQENAnyOMTcSLCgJAPG17NqrU1se9HIWstDM/edit?usp=sharing)\n",
    "1. Relevance of Text (NLP)\n",
    "    * We can use Precision to mearsure the relevance\n",
    "        - see Clotilde's note for reference and description\n",
    "        - number of relevant articles / total number of articles\n",
    "                \n",
    "    * WordNet / Merriam-Webster dictionary can identify synonyms and similar words in queries and contents\n",
    "        - Princeton WordNet web (http://wordnetweb.princeton.edu/perl/webwn)\n",
    "            \n",
    "2. SEO - Need a tool such as HRS (Hiva's note has more details)\n",
    "    * How to measure?\n",
    "        \n",
    "3. Date\n",
    "\n",
    "* If use TF-IDF, we can do Clustering / Classification / Machine Learning to let python learn what's relevant\n",
    "\n",
    "\n",
    "### What to do:\n",
    "text analysis (NLP)\n",
    "1. Learn more about TF-IDF\n",
    "2. WordNet / Merriam-Webster dictionary\n",
    "\n",
    "Presentation (Mon/Tue 10 min check-in)\n",
    "    What we did\n",
    "    What we will do\n",
    "    \n",
    "Sumin: integrate date fetching step in the scraping algorithm (done)\n",
    "Make a list of variables and document what's been done for each variable (done):\n",
    "    https://docs.google.com/document/d/1HDImwWFsQENAnyOMTcSLCgJAPG17NqrU1se9HIWstDM/edit?usp=sharing\n",
    "\n",
    "\n",
    "Meeting with Sogol/Sana\n",
    "1. Ask about SEO how to measure it!\n",
    "2. Date as a variable\n",
    "3. Checking in\n",
    "\n",
    "Q. What if we only have less than 20 search results?\n",
    "\n",
    "A: We need to come up with a solution. It can be because of (1) query being too specific, (2) location information\n",
    "##### \n",
    "\n",
    "Q: Do we actually want north American information?\n",
    "\n",
    "A: No. We want more general information, not only for north America\n",
    "##### \n",
    "\n",
    "Q: Can we change query with words in similar meaning word group\n",
    "\n",
    "A: Yes we can, but it's a bit more of group 1's problem.\n",
    "##### \n",
    "\n",
    "Q: Any available NLP library to recognize synonyms/similar words, other than WordNet and Merriam-Webster?\n",
    "\n",
    "A: Sana can help!\n",
    "##### \n",
    "\n",
    "Q: Can stability measurement be a variable?\n",
    "\n",
    "A: Yes! It needs some \n",
    "\n",
    "##### \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e6a94e",
   "metadata": {},
   "source": [
    "### <font color = 'blue'> June 12, 2024 </font>\n",
    "### What to do:\n",
    "Sumin: exploring clustering / how to identify keywords\n",
    "\n",
    "Clotilde: searching for previous works\n",
    "\n",
    "Irushi: reviewing the code / think about variables\n",
    "\n",
    "Hiva: searching about optimization\n",
    "\n",
    "Common:\n",
    "1. Subvariables for relevance of the top 20 results with the Sogol's queries (no need to use all 100 of them for now)\n",
    "    * how to measure how much broad / specific information the articles have.\n",
    "2. How to choose keywords (we need to collect some data from articles) - Sogol has some data?\n",
    "\n",
    "\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec4f1a",
   "metadata": {},
   "source": [
    "Our thoughts on evaluating the search engine results:\n",
    "\n",
    "* I think we need some data to train our algorithm, especially to identify keywords and features of relevant/irrelevant articles. We can easily collect information from news search! (or Sogol and Sana may be able to provide us some information)\n",
    "\n",
    "### Variables (to determine the best/worst search engine):\n",
    "1. The number of relevant articles among top 20 results\n",
    "    * Give weights for the position of the article? (1st result has more weight and 20th result has less)\n",
    "2. how much specific information the relevant articles contain (general info only or specific info included)\n",
    "    * how well the search engines do for Broad / Specific prompts\n",
    "    * misreporting / underreporting any difference in results?\n",
    "3. dates of the articles (how old the articles are)\n",
    "4. how many different incidents show up (not every article is about the same incident)\n",
    "\n",
    "\n",
    "### Techniques for preliminary screen (removing irrelevent articles):\n",
    "1. keyword evaluation\n",
    "    * Frequency of the keywords OR how many keywords included (Clotilde's function) in the title and content (maybe not the whole content if it's long, we can sample some part for efficiency) - Sana's doc also mentioned Term Frequency-Inverse Document Frequency Algorithm (https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency/)\n",
    "    * Naive Bayes model (similar to spam email detection, we can detect irrelevant articles) - but this needs the keyword statistics (probability) information / training data\n",
    "    \n",
    "2. Clustering\n",
    "    * Cluster the articles with similarity and sort out irrelevant articles - also need some training data\n",
    "    * Non-numerical data need to be carefully pre-processed to obtain the clusters we want. For example, usually the words should be mapped to numerical values (maybe there's some python library does the job?)\n",
    "    * From Sana's file, it seems like some engines (if not all) make clusters for their results so they can show different results. We can make our own clusters to gather relevant information.\n",
    "\n",
    "\n",
    "### Next thing to think about / questions:\n",
    "1. How to screen 'biased' information\n",
    "    * Penalize certain keywords such as politics, (we need to consider different things)\n",
    "2. Specific information (Vessel, captain's name, where it happend, what happened)\n",
    "    * How to identify them in the articles\n",
    "    * How to measure/compare the amount of information in an article numerically\n",
    "3. About regional biases, are we actually focus on Vancouver/North West America? Or anywhere in the world?\n",
    "4. Can we get certain information like click rate / scroll speed / time on page? (not sure if we would need them though)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ade545d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e39e0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
