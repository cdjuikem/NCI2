{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580ff700",
   "metadata": {},
   "source": [
    "### Information evaluation:\n",
    "Searching for \n",
    "1. IMO: 7 digit number\n",
    "2. MMSI: 9 digit number\n",
    "3. Ship, Company, or Peopleâ€™s name : information about who is involved (crew/captain/police)\n",
    "4. country's name: it can be offence location / flag / where the offender from etc\n",
    "5. fish names: species involved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3354415d",
   "metadata": {},
   "source": [
    "#### 1. Searching IMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2e4b4097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# some example text \n",
    "text = \"Here are some numbers: 1234, 12312, 1423124125, 1231241232, 1231244, 2384822, 210392892\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "718e2a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1231244', '2384822']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def find_imo(content):    \n",
    "    # IMO is a 7-digit number (exactly 7-digit)\n",
    "    imo_pattern = r'\\b\\d{7}\\b'\n",
    "    \n",
    "    # find all 7-digit numbers in the content \n",
    "    imo_list = re.findall(imo_pattern, content)\n",
    "    \n",
    "    return imo_list\n",
    "\n",
    "find_imo(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddaf90c",
   "metadata": {},
   "source": [
    "#### 2. Searching MMSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "040111f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['210392892']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_mmsi(content):    \n",
    "    # regular expression for a 9-digit number (exactly 9-digit)\n",
    "    mmsi_pattern = r'\\b\\d{9}\\b'\n",
    "    \n",
    "    # find all 9-digit numbers in the content \n",
    "    mmsi_list = re.findall(mmsi_pattern, content)\n",
    "    \n",
    "    return mmsi_list\n",
    "\n",
    "find_mmsi(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e502d48",
   "metadata": {},
   "source": [
    "#### 3. Ship, company, people's name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94a80520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def find_involved_parties_spacy(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    names = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['PERSON', 'ORG', 'NORP']: # NORP is about nationality/religious/political group\n",
    "            names.append(ent.text)\n",
    "    return names\n",
    "\n",
    "# country's name / location\n",
    "def find_location(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "    company_names = []\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['LOC', 'GPE']: # location labels\n",
    "            company_names.append(ent.text)\n",
    "\n",
    "    return company_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c189b25",
   "metadata": {},
   "source": [
    "##### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e93270c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "involved parties: ['Sambro', 'Casey Henneberry', 'ALS Fisheries', 'Halifax', 'Elizabeth Buckle', 'Henneberry', 'Sambro', 'Henneberry', 'Law Fisheries', 'ALS Fisheries', 'ALS Fisheries', 'the Department of Fisheries', 'Oceans']\n",
      "location: ['N.S.']\n"
     ]
    }
   ],
   "source": [
    "# Sample text for demonstration. The article is from:\n",
    "# https://www.cbc.ca/news/canada/nova-scotia/n-s-boat-captain-fined-fisheries-violations-1.6965198\n",
    "text = \"\"\"\n",
    "A boat captain from Sambro, N.S., with a history of fishery convictions has been fined $60,000 and banned from fishing for six months for five violations that included a secret, middle-of-the-night offload of halibut.\n",
    "\n",
    "The case involved misreporting of halibut, hake and cod catch from trips on board the fishing boat Ivy Lew between May 2019 and June 2020.\n",
    "\n",
    "Casey Henneberry, 40, and ALS Fisheries and Law Fisheries were found guilty last October by Halifax provincial court Judge Elizabeth Buckle.\n",
    "\n",
    "The sentence was handed down in court last month and posted this week.\n",
    "\n",
    "\"Mr. Henneberry's offending conduct is that he inaccurately logged and hailed weight of groundfish on four trips over approximately one year and on one of those trips, he illegally off-loaded $40,000 worth of halibut, intending to sell it,\" Buckle said in her written sentence.\n",
    "\n",
    "On that trip, DFO officers were observing the Ivy Lew and intercepted the illegal off-load in Sambro. During the attempted arrests of those involved, Henneberry fled and was arrested later, the judge noted in sentencing.\n",
    "\n",
    "During this period the groundfish licence was held first by Law Fisheries and then ALS Fisheries. The companies were fined $55,000 and $10,000 respectively for failing to ensure licence conditions were complied with.\n",
    "\n",
    "ALS Fisheries owns the Ivy Lew, which has been held for the past three years by the Department of Fisheries and Oceans, likely as security on any fine.\n",
    "\n",
    "The company has continued to pay on the $1-million mortgage on the vessel.\"\"\"\n",
    "\n",
    "print(\"involved parties:\", find_involved_parties_spacy(text))\n",
    "print(\"location:\", find_location(text))\n",
    "\n",
    "#### Sambro and Halifax are cities..\n",
    "#### Seems like they don't know much about Canadian cities ðŸ˜‚\n",
    "### maybe we should combine these two, or find a better library.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599cc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d19bdf99",
   "metadata": {},
   "source": [
    "#### 5. Searching fish names (in progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e59fda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "### handpicking common fish names for fishing\n",
    "fish_words = {'salmon', 'tuna', 'shark', 'whale', 'crab', 'lobster', 'shrimp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9eed7b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fish names found in WordNet:\n",
      "bony fish\n",
      "bottom-feeder\n",
      "bottom-dweller\n",
      "bottom lurkers\n",
      "cartilaginous fish\n",
      "chondrichthian\n",
      "climbing perch\n",
      "Anabas testudineus\n",
      "A. testudineus\n",
      "fingerling\n",
      "food fish\n",
      "game fish\n",
      "sport fish\n",
      "mouthbreeder\n",
      "northern snakehead\n",
      "rough fish\n",
      "spawner\n",
      "young fish\n",
      "alewife\n",
      "anchovy\n",
      "eel\n",
      "haddock\n",
      "hake\n",
      "mullet\n",
      "grey mullet\n",
      "gray mullet\n",
      "panfish\n",
      "rock salmon\n",
      "salmon\n",
      "schrod\n",
      "scrod\n",
      "shad\n",
      "smelt\n",
      "stockfish\n",
      "trout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sumin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def search_fish_names():\n",
    "    fish_names = []\n",
    "    # Search for synsets directly related to 'fish'\n",
    "    synsets = wn.synsets('fish', pos=wn.NOUN)\n",
    "\n",
    "    for synset in synsets:\n",
    "        # Retrieve hyponyms (more specific terms) of each 'fish' synset\n",
    "        hyponyms = synset.hyponyms()\n",
    "        for hyponym in hyponyms:\n",
    "            # Retrieve lemmas (actual words) of each hyponym\n",
    "            for lemma in hyponym.lemmas():\n",
    "                fish_names.append(lemma.name().replace('_', ' '))\n",
    "\n",
    "    return fish_names\n",
    "\n",
    "# Example usage:\n",
    "fish_names = search_fish_names()\n",
    "print(\"Fish names found in WordNet:\")\n",
    "for name in fish_names:\n",
    "    print(name)\n",
    "\n",
    "## not covering all species.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e38ee0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fish names found in WordNet:\n",
      "bony fish\n",
      "crossopterygian\n",
      "lobefin\n",
      "lobe-finned fish\n",
      "lungfish\n",
      "teleost fish\n",
      "teleost\n",
      "teleostan\n",
      "bottom-feeder\n",
      "bottom-dweller\n",
      "mullet\n",
      "bottom lurkers\n",
      "cartilaginous fish\n",
      "chondrichthian\n",
      "elasmobranch\n",
      "selachian\n",
      "holocephalan\n",
      "holocephalian\n",
      "climbing perch\n",
      "Anabas testudineus\n",
      "A. testudineus\n",
      "fingerling\n",
      "food fish\n",
      "barracouta\n",
      "snoek\n",
      "groundfish\n",
      "bottom fish\n",
      "herring\n",
      "Clupea harangus\n",
      "salmon\n",
      "sardine\n",
      "sea bass\n",
      "shad\n",
      "snapper\n",
      "sole\n",
      "trout\n",
      "tuna\n",
      "tunny\n",
      "whitefish\n",
      "game fish\n",
      "sport fish\n",
      "mouthbreeder\n",
      "northern snakehead\n",
      "rough fish\n",
      "spawner\n",
      "young fish\n",
      "brit\n",
      "britt\n",
      "parr\n",
      "parr\n",
      "whitebait\n",
      "alewife\n",
      "anchovy\n",
      "eel\n",
      "elver\n",
      "smoked eel\n",
      "haddock\n",
      "finnan haddie\n",
      "finnan haddock\n",
      "finnan\n",
      "smoked haddock\n",
      "hake\n",
      "mullet\n",
      "grey mullet\n",
      "gray mullet\n",
      "panfish\n",
      "rock salmon\n",
      "salmon\n",
      "Atlantic salmon\n",
      "chinook salmon\n",
      "chinook\n",
      "king salmon\n",
      "kippered salmon\n",
      "red salmon\n",
      "sockeye\n",
      "sockeye salmon\n",
      "silver salmon\n",
      "coho salmon\n",
      "coho\n",
      "cohoe\n",
      "smoked salmon\n",
      "schrod\n",
      "scrod\n",
      "shad\n",
      "smelt\n",
      "American smelt\n",
      "rainbow smelt\n",
      "European smelt\n",
      "sparling\n",
      "stockfish\n",
      "trout\n",
      "rainbow trout\n",
      "sea trout\n",
      "salmon trout\n",
      "angle\n",
      "fly-fish\n",
      "flyfish\n",
      "troll\n",
      "brail\n",
      "crab\n",
      "net fish\n",
      "prawn\n",
      "rail\n",
      "scallop\n",
      "scollop\n",
      "seine\n",
      "shark\n",
      "shrimp\n",
      "still-fish\n",
      "trawl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sumin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def search_fish_names():\n",
    "    fish_names = []\n",
    "    # Search for synsets related to 'fish'\n",
    "    fish_synsets = wn.synsets('fish')\n",
    "\n",
    "    for synset in fish_synsets:\n",
    "        # Retrieve all hyponyms (more specific terms) recursively\n",
    "        hyponyms = synset.hyponyms()\n",
    "        for hyponym in hyponyms:\n",
    "            # Iterate through all lemmas (actual words) of each hyponym\n",
    "            for lemma in hyponym.lemmas():\n",
    "                fish_names.append(lemma.name().replace('_', ' '))\n",
    "\n",
    "            # Additionally, retrieve all hyponyms of each hyponym recursively\n",
    "            nested_hyponyms = hyponym.hyponyms()\n",
    "            for nested_hyponym in nested_hyponyms:\n",
    "                for lemma in nested_hyponym.lemmas():\n",
    "                    fish_names.append(lemma.name().replace('_', ' '))\n",
    "\n",
    "    return fish_names\n",
    "\n",
    "# Example usage:\n",
    "fish_names = search_fish_names()\n",
    "print(\"Fish names found in WordNet:\")\n",
    "for name in fish_names:\n",
    "    print(name)\n",
    "\n",
    "    \n",
    "# maybe not covering all species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc96dbdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239c36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
