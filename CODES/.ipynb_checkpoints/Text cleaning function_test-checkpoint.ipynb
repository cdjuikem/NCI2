{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "add15dbc",
   "metadata": {},
   "source": [
    "### Hiva's functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a734089",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#### Synonym and derived forms\n",
    "########################################################\n",
    "########################################################\n",
    "# Synonym (copied 240619)\n",
    "# required libraries:\n",
    "import nltk \n",
    "from nltk.corpus import wordnet \n",
    "import requests\n",
    "\n",
    "def get_synonyms(word):\n",
    "    url = f\"https://api.datamuse.com/words?rel_syn={word}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        synonyms = [entry['word'] for entry in data]\n",
    "        return synonyms\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        return []\n",
    "\n",
    "########################################################\n",
    "# related words (copied 240619)\n",
    "def get_related_words(word, limit=60, topics=None):\n",
    "    url = f\"https://api.datamuse.com/words?ml={word}&max={limit}\"\n",
    "    \n",
    "    if topics:\n",
    "        url += f\"&topics={topics}\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        related_words = [entry['word'] for entry in data]\n",
    "        return related_words\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code)\n",
    "        return []\n",
    "\n",
    "\n",
    "########################################################\n",
    "# A function to check if a word is in the list or not (copied 240619)    \n",
    "def check_word_in_list(word, word_list):\n",
    "    if word in word_list:\n",
    "        return f\"'{word}' is in the list.\"\n",
    "    else:\n",
    "        return f\"'{word}' is not in the list.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94ea2b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VBD': ('hid',),\n",
       " 'VBN': ('hidden',),\n",
       " 'VBG': ('hiding',),\n",
       " 'VBZ': ('hides',),\n",
       " 'VB': ('hide',),\n",
       " 'VBP': ('hide',)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from lemminflect import getInflection, getAllInflections    \n",
    "getAllInflections('hide', upos='VERB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5796ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All inflections of 'hide' including base form:\n",
      "{'VBD': ('hid',), 'VBN': ('hidden',), 'VBG': ('hiding',), 'VBZ': ('hides',), 'VB': ('hide',), 'VBP': ('hide',)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lemminflect\n",
    "\n",
    "word = 'hide'\n",
    "\n",
    "# Get inflections for 'hide' as a verb\n",
    "inflections = lemminflect.getAllInflections(word, upos='VERB')\n",
    "\n",
    "# Add the base form 'hide' to the list of inflections\n",
    "#inflections.append(word)\n",
    "\n",
    "print(\"All inflections of 'hide' including base form:\")\n",
    "print(inflections)\n",
    "type(inflections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01484370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hid <class 'str'>\n",
      "hidden <class 'str'>\n",
      "hiding <class 'str'>\n",
      "hides <class 'str'>\n",
      "hide <class 'str'>\n",
      "hide <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "forms = list(inflections.values())\n",
    "\n",
    "for item in forms:\n",
    "    print(item[0], type(item[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc07148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "#### lemminflect does not return anything when given a non-verb word\n",
    "inflections = lemminflect.getAllInflections('teacher', upos='VERB')\n",
    "print(inflections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0b49d5",
   "metadata": {},
   "source": [
    "#### Given a word, \"form_list\" returns a list of all forms of the verb. If not a verb, it returns a list only contains the word itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4e160c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lemminflect\n",
    "\n",
    "def form_list(word):\n",
    "    # Get all inflections for the word as a verb\n",
    "    inflections = lemminflect.getAllInflections(word, upos='VERB')\n",
    "    \n",
    "    # Check if the word or any of its inflections are in the list of verb inflections\n",
    "    forms = list(inflections.values())\n",
    "    form_set = set()\n",
    "    for item in forms:\n",
    "        form_set.add(item[0])\n",
    "    if form_set == {}:\n",
    "        return word\n",
    "    else:\n",
    "        return list(form_set)\n",
    "\n",
    "form_list('apple')\n",
    "\n",
    "form_list('underreport')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81bcef9",
   "metadata": {},
   "source": [
    "### From here, working on the text cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d18d8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walked ['walk', 'walked', 'walks', 'walking']\n",
      "bought ['buys', 'buy', 'buying', 'bought']\n",
      "caught ['catch', 'catches', 'catching', 'caught']\n",
      "misreporting []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'He walked quickly to the store and bought some groceries. Vessels caught misreporting catches'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Let's make a new collection of cleaning functions:\n",
    "import re\n",
    "def collect_verb(text):\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "    verbs = [word for word, tag in pos_tags if tag.startswith('V')]\n",
    "    return verbs\n",
    "\n",
    "def rep_word_text(text):\n",
    "    verb_list = collect_verb(text)\n",
    "    if verb_list == []:\n",
    "        return text\n",
    "    else:\n",
    "        for verb in verb_list:\n",
    "            verb_forms = form_list(lemmatizer.lemmatize(verb, pos='v'))\n",
    "            print(verb, verb_forms)\n",
    "            if len(verb_forms) != 1:\n",
    "                new_text = clean_word(text, verb_forms)\n",
    "            else:\n",
    "                new_text = text\n",
    "        return new_text\n",
    "    \n",
    "text = \"He walked quickly to the store and bought some groceries. Vessels caught misreporting catches\"\n",
    "rep_word_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02d5a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### functions that we had:\n",
    "misreport = ['misreport', 'misreports', 'misreporting', 'misreported']\n",
    "underreport = ['underreport', 'underreports', 'underreporting', 'underreported']\n",
    "\n",
    "def clean_word(text, group):\n",
    "    if len(group) == 1:\n",
    "        return text\n",
    "    elif len(group) != 1:\n",
    "        updated_text = text\n",
    "        for i in range(1,len(group)):\n",
    "            pattern = r'\\b{}\\b'.format(re.escape(group[i]))\n",
    "            updated_text = re.sub(pattern, group[0], updated_text)\n",
    "        return updated_text\n",
    "    else:\n",
    "        print(\"The word group is empty\")\n",
    "        return None\n",
    "\n",
    "##### Here word_group_list is the list of word groups.\n",
    "def rep_word_text(text, word_group_list):\n",
    "    if len(word_group_list) != 0:\n",
    "        new_text = text\n",
    "        for i in range(len(word_group_list)):\n",
    "            new_text = clean_word(new_text, word_group_list[i])\n",
    "        return new_text\n",
    "    else:\n",
    "        print(\"the word group list is invalid\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f018e8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs in the text: ['walked', 'bought', 'caught', 'misreporting']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Sample text\n",
    "text = \"He walked quickly to the store and bought some groceries. Vessels caught misreporting catches\"\n",
    "\n",
    "# Tokenize the text into words\n",
    "words = word_tokenize(text)\n",
    "\n",
    "# Perform Part-of-Speech (POS) tagging\n",
    "\n",
    "\n",
    "# Extract verbs based on POS tags\n",
    "verbs = [word for word, tag in pos_tags if tag.startswith('V')]\n",
    "\n",
    "# Print the list of verbs\n",
    "print(\"Verbs in the text:\", verbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abd8e09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9c9fccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forms of 'misreporting': {'misreportings', 'misreporting', 'misreportinging', 'misreportinged'}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2911a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
