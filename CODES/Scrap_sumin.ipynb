{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a84bf1",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2f13329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef12a389",
   "metadata": {},
   "source": [
    "###  Set url to scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2aa16567",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = requests.get('https://cimsec.org/lead-the-fight-against-climate-change-and-transnational-crime-in-the-indian-ocean/')\n",
    "soup = BeautifulSoup(url.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02544f30",
   "metadata": {},
   "source": [
    "### Scrap the content and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f4a2952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "content = soup.find_all(\"div\", class_ = 'entry-content')\n",
    "\n",
    "def clean_text(text):\n",
    "    # Text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters using regular expression\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return cleaned_text\n",
    "\n",
    "for paragraph in content:\n",
    "    text = paragraph.get_text(separator='\\n')\n",
    "    text = clean_text(text)\n",
    "    text_word = text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218ce708",
   "metadata": {},
   "source": [
    "### Count the frequency of each word appeared in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "49d387bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_count = Counter(text_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81113836",
   "metadata": {},
   "source": [
    "### Using pandas to form a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f9dd96f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a8317009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       word  count\n",
      "0     notes      1\n",
      "1        to     16\n",
      "2       the     32\n",
      "3       new      1\n",
      "4       cno      2\n",
      "..      ...    ...\n",
      "258    port      1\n",
      "259    city      1\n",
      "260   lanka      1\n",
      "261     via      1\n",
      "262  xinhua      1\n",
      "\n",
      "[263 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(word_count.items(), columns = ['word', 'count'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d437c313",
   "metadata": {},
   "source": [
    "#### I searched for \"fish crime\", \"ocean crime\", \"fish crime ship\", etc on Google. \n",
    "#### Sometimes, the results contain some irrelevant articles such as \"stolen fish from restaurants\".\n",
    "#### My first thought on collecting relevant information is to use the naive Bayes model like a spam-email detector.\n",
    "####\n",
    "#### A technical question: Can we automatically collect the top 20 results from a search engine, instead of doing it one-by-one like my code?\n",
    "#### If we can do, that can save us a lot of time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
